{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q8JeiQCj6GC-"
      },
      "outputs": [],
      "source": [
        "# Copyright 2022 Intrinsic Innovation LLC.\n",
        "#\n",
        "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "#     http://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GzXpkXvF3f3N"
      },
      "source": [
        "We use PGMax to reimplement the binary deconvolution experiment presented in the Section 5.6 of the [Perturb-and-max-product (PMP)](https://proceedings.neurips.cc/paper/2021/hash/07b1c04a30f798b5506c1ec5acfb9031-Abstract.html) Neurips 2021 paper.\n",
        "\n",
        "The original implementation is available on the [GitHub repository of the paper.](https://github.com/vicariousinc/perturb_and_max_product/blob/master/experiments/exp6_convor.py)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BGB_lzKmtQvY"
      },
      "outputs": [],
      "source": [
        "# # Uncomment this block if running on colab.research.google.com\n",
        "# !pip install git+https://github.com/deepmind/PGMax.git\n",
        "# !wget https://raw.githubusercontent.com/deepmind/PGMax/main/examples/example_data/conv_problem.npz\n",
        "# !mkdir example_data\n",
        "# !mv conv_problem.npz  example_data/"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XBLe3jnh3Z5o"
      },
      "outputs": [],
      "source": [
        "import functools\n",
        "from collections import defaultdict\n",
        "\n",
        "import jax\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from scipy.special import logit\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "############\n",
        "# Load PGMax\n",
        "from pgmax import fgraph, fgroup, infer, vgroup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lGt8c9Fd3hjb"
      },
      "outputs": [],
      "source": [
        "def plot_images(images, display=True, nr=None):\n",
        "  \"Useful function for visualizing several images.\"\n",
        "  n_images, H, W = images.shape\n",
        "  images = images - images.min()\n",
        "  images /= images.max() + 1e-10\n",
        "\n",
        "  if nr is None:\n",
        "    nr = nc = np.ceil(np.sqrt(n_images)).astype(int)\n",
        "  else:\n",
        "    nc = n_images // nr\n",
        "    assert n_images == nr * nc\n",
        "  big_image = np.ones(((H + 1) * nr + 1, (W + 1) * nc + 1, 3))\n",
        "  big_image[..., :3] = 0\n",
        "  big_image[:: H + 1] = [0.5, 0, 0.5]\n",
        "\n",
        "  im = 0\n",
        "  for r in range(nr):\n",
        "    for c in range(nc):\n",
        "      if im \u003c n_images:\n",
        "        big_image[\n",
        "            (H + 1) * r + 1 : (H + 1) * r + 1 + H,\n",
        "            (W + 1) * c + 1 : (W + 1) * c + 1 + W,\n",
        "            :,\n",
        "        ] = images[im, :, :, None]\n",
        "        im += 1\n",
        "\n",
        "  if display:\n",
        "    plt.figure(figsize=(10, 10))\n",
        "    plt.imshow(big_image, interpolation=\"none\")\n",
        "    plt.axis(\"off\")\n",
        "  return big_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A7YzancH39cp"
      },
      "source": [
        "### Load the data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBsEGr6u3_P0"
      },
      "source": [
        "Our binary 2D convolution generative model uses two set of binary variables to form a set of binary images X:\n",
        " - a set W of 2D binary features shared across images,\n",
        " - a set S of binary indicator variables representing whether each feature is present at each possible image location.\n",
        "\n",
        "Each binary entry of W and S is modeled with an independent Bernoulli prior. S and W are then combined by convolution, placing the features defined by W at the locations specified by S in order to form the image.\n",
        "\n",
        "We load the dataset of 100 images used in the PMP paper.\n",
        "We only keep the first 20 images here for the sake of speed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9CzNYmlL37Zm"
      },
      "outputs": [],
      "source": [
        "# Load data\n",
        "folder_name = \"example_data/\"\n",
        "data = np.load(open(folder_name + \"conv_problem.npz\", 'rb'), allow_pickle=True)\n",
        "W_gt = data[\"W\"]\n",
        "X_gt = data[\"X\"]\n",
        "X_gt = X_gt[:20]\n",
        "\n",
        "_ = plot_images(X_gt[:, 0], nr=4)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s32VWzDj49Gb"
      },
      "source": [
        "We also visualize the four 2D binary features used to generate the images above.\n",
        "\n",
        "We aim at recovering these binary features using PGMax."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mD5TagAh400f"
      },
      "outputs": [],
      "source": [
        "_ = plot_images(W_gt[0], nr=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mzczRvwY5Aac"
      },
      "source": [
        "### Construct variable grid, initialize factor graph, and add factors"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wz1br27z5Cs8"
      },
      "source": [
        "Our factor graph naturally includes the binary features W, the binary indicators of features locations S and the binary images obtained by convolution X.\n",
        "\n",
        "To generate X from W and S, we observe that a binary convolution can be represented by two set of logical factors:\n",
        " - a first set of ANDFactors, which combine the joint activations in W and S. We store the children of these ANDFactors in an auxiliary variable SW\n",
        " - a second set of ORFactors, which maps SW to X and model (binary) features overlapping.\n",
        "\n",
        "See Section 5.6 of the [PMP paper](https://proceedings.neurips.cc/paper/2021/hash/07b1c04a30f798b5506c1ec5acfb9031-Abstract.html) for more details."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NiEM0ROe4-dg"
      },
      "outputs": [],
      "source": [
        "# The dimensions of W used for the generation of X were (4, 5, 5) but we set them to (5, 6, 6)\n",
        "# to simulate a more realistic scenario in which we do not know their ground truth values\n",
        "n_feat, feat_height, feat_width = 5, 6, 6\n",
        "\n",
        "n_images, n_chan, im_height, im_width = X_gt.shape\n",
        "s_height = im_height - feat_height + 1\n",
        "s_width = im_width - feat_width + 1\n",
        "\n",
        "# Binary features\n",
        "W = vgroup.NDVarArray(num_states=2, shape=(n_chan, n_feat, feat_height, feat_width))\n",
        "\n",
        "# Binary indicators of features locations\n",
        "S = vgroup.NDVarArray(num_states=2, shape=(n_images, n_feat, s_height, s_width))\n",
        "\n",
        "# Auxiliary binary variables combining W and S\n",
        "SW = vgroup.NDVarArray(\n",
        "    num_states=2,\n",
        "    shape=(n_images, n_chan, im_height, im_width, n_feat, feat_height, feat_width),\n",
        ")\n",
        "\n",
        "# Binary images obtained by convolution\n",
        "X = vgroup.NDVarArray(num_states=2, shape=X_gt.shape)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pd5wwvZy5I9c"
      },
      "source": [
        "For computation efficiency, we construct large FactorGroups instead of individual factors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q_EFdqn65B0J"
      },
      "outputs": [],
      "source": [
        "# Factor graph\n",
        "fg = fgraph.FactorGraph(variable_groups=[S, W, SW, X])\n",
        "\n",
        "# Define the ANDFactors\n",
        "variables_for_ANDFactors = []\n",
        "variables_for_ORFactors_dict = defaultdict(list)\n",
        "for idx_img in tqdm(range(n_images)):\n",
        "  for idx_chan in range(n_chan):\n",
        "    for idx_s_height in range(s_height):\n",
        "      for idx_s_width in range(s_width):\n",
        "        for idx_feat in range(n_feat):\n",
        "          for idx_feat_height in range(feat_height):\n",
        "            for idx_feat_width in range(feat_width):\n",
        "              idx_img_height = idx_feat_height + idx_s_height\n",
        "              idx_img_width = idx_feat_width + idx_s_width\n",
        "              SW_var = SW[\n",
        "                  idx_img,\n",
        "                  idx_chan,\n",
        "                  idx_img_height,\n",
        "                  idx_img_width,\n",
        "                  idx_feat,\n",
        "                  idx_feat_height,\n",
        "                  idx_feat_width,\n",
        "              ]\n",
        "\n",
        "              variables_for_ANDFactor = [\n",
        "                  S[idx_img, idx_feat, idx_s_height, idx_s_width],\n",
        "                  W[idx_chan, idx_feat, idx_feat_height, idx_feat_width],\n",
        "                  SW_var,\n",
        "              ]\n",
        "              variables_for_ANDFactors.append(variables_for_ANDFactor)\n",
        "\n",
        "              X_var = X[idx_img, idx_chan, idx_img_height, idx_img_width]\n",
        "              variables_for_ORFactors_dict[X_var].append(SW_var)\n",
        "\n",
        "# Add ANDFactorGroup, which is computationally efficient\n",
        "AND_factor_group = fgroup.ANDFactorGroup(variables_for_ANDFactors)\n",
        "fg.add_factors(AND_factor_group)\n",
        "\n",
        "# Define the ORFactors\n",
        "variables_for_ORFactors = [\n",
        "    list(tuple(variables_for_ORFactors_dict[X_var]) + (X_var,))\n",
        "    for X_var in variables_for_ORFactors_dict\n",
        "]\n",
        "\n",
        "# Add ORFactorGroup, which is computationally efficient\n",
        "OR_factor_group = fgroup.ORFactorGroup(variables_for_ORFactors)\n",
        "fg.add_factors(OR_factor_group)\n",
        "\n",
        "for factor_type, factor_groups in fg.factor_groups.items():\n",
        "  if len(factor_groups) \u003e 0:\n",
        "    assert len(factor_groups) == 1\n",
        "    print(f\"The factor graph contains {factor_groups[0].num_factors} {factor_type.__name__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c6trpp6j5NJR"
      },
      "source": [
        "### Run inference and visualize results"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8vrqD1V75O7V"
      },
      "source": [
        "PMP perturbs the model by adding Gumbel noise to unary potentials, then samples from the joint posterior *p(W, S | X)*.\n",
        "\n",
        "Note that this posterior is highly multimodal: permuting the first dimension of W and the second dimension of S\n",
        "in the same manner does not change X, so this naturally results in multiple equivalent modes."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CTaBDBsd5KpH"
      },
      "outputs": [],
      "source": [
        "bp = infer.BP(fg.bp_state, temperature=0.0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sp-JKekZ5Ssv"
      },
      "source": [
        "We first compute the evidence without perturbation, similar to the PMP paper."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XR1Vcl5z5Qmi"
      },
      "outputs": [],
      "source": [
        "pW = 0.25\n",
        "pS = 1e-75\n",
        "pX = 1e-100\n",
        "\n",
        "# Sparsity inducing priors for W and S\n",
        "uW = np.zeros((W.shape) + (2,))\n",
        "uW[..., 1] = logit(pW)\n",
        "\n",
        "uS = np.zeros((S.shape) + (2,))\n",
        "uS[..., 1] = logit(pS)\n",
        "\n",
        "# Likelihood the binary images given X\n",
        "uX = np.zeros((X_gt.shape) + (2,))\n",
        "uX[..., 0] = (2 * X_gt - 1) * logit(pX)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ovREZGV5V8q"
      },
      "source": [
        "We draw a batch of samples from the posterior in parallel by transforming `run_bp`/`get_beliefs` with `jax.vmap`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ejpW-qw05T65"
      },
      "outputs": [],
      "source": [
        "np.random.seed(seed=0)\n",
        "n_samples = 4\n",
        "\n",
        "bp_arrays = jax.vmap(bp.init, in_axes=0, out_axes=0)(\n",
        "    evidence_updates={\n",
        "        S: uS[None] + np.random.gumbel(size=(n_samples,) + uS.shape),\n",
        "        W: uW[None] + np.random.gumbel(size=(n_samples,) + uW.shape),\n",
        "        SW: np.zeros(shape=(n_samples,) + SW.shape),\n",
        "        X: uX[None] + np.zeros(shape=(n_samples,) + uX.shape),\n",
        "    },\n",
        ")\n",
        "\n",
        "bp_arrays = jax.vmap(\n",
        "    functools.partial(bp.run_bp, num_iters=100, damping=0.5),\n",
        "    in_axes=0,\n",
        "    out_axes=0,\n",
        ")(bp_arrays)\n",
        "\n",
        "beliefs = jax.vmap(bp.get_beliefs, in_axes=0, out_axes=0)(bp_arrays)\n",
        "map_states = infer.decode_map_states(beliefs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sl3pPm-l5ZgZ"
      },
      "source": [
        "Visualizing the MAP decoding, we see that we have 4 good random samples (one per row) from the posterior!\n",
        "\n",
        "Because we have used one extra feature for inference, each posterior sample recovers the 4 basic features used to generate the images, and includes an extra symbol."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vpR_z5Xc5XnB"
      },
      "outputs": [],
      "source": [
        "_ = plot_images(map_states[W].reshape(-1, feat_height, feat_width), nr=n_samples)"
      ]
    }
  ],
  "metadata": {},
  "nbformat": 4,
  "nbformat_minor": 0
}
